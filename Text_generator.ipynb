{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77892196",
   "metadata": {},
   "source": [
    "Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "014f8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26b00a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "import requests\n",
    "filename = \"samples.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2003f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "# dataset file path\n",
    "FILE_PATH = \"sample1.txt\"\n",
    "BASENAME = os.path.basename(FILE_PATH)\n",
    "# read the data\n",
    "text = open(FILE_PATH, encoding=\"utf-8\").read()\n",
    "# remove caps, comment this code if you want uppercase characters as well\n",
    "text = text.lower()\n",
    "# remove punctuation\n",
    "text = text.translate(str.maketrans(\"\", \"\", punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "663ea4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_chars: \n",
      " 0123456789abcdefghijklmnopqrstuvwxyz﻿\n",
      "Number of characters: 158596\n",
      "Number of unique characters: 39\n"
     ]
    }
   ],
   "source": [
    "# print some stats\n",
    "n_chars = len(text)\n",
    "vocab = ''.join(sorted(set(text)))\n",
    "print(\"unique_chars:\", vocab)\n",
    "n_unique_chars = len(vocab)\n",
    "print(\"Number of characters:\", n_chars)\n",
    "print(\"Number of unique characters:\", n_unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8359a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that converts characters to integers\n",
    "char2int = {c: i for i, c in enumerate(vocab)}\n",
    "# dictionary that converts integers to characters\n",
    "int2char = {i: c for i, c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe544b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these dictionaries for later generation\n",
    "pickle.dump(char2int, open(f\"{BASENAME}-char2int.pickle\", \"wb\"))\n",
    "pickle.dump(int2char, open(f\"{BASENAME}-int2char.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8086fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all text into integers\n",
    "encoded_text = np.array([char2int[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4d666c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct tf.data.Dataset object\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cc007ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 ﻿\n",
      "27 p\n",
      "29 r\n",
      "26 o\n",
      "21 j\n",
      "16 e\n",
      "14 c\n",
      "31 t\n"
     ]
    }
   ],
   "source": [
    "# print first 5 characters\n",
    "for char in char_dataset.take(8):\n",
    "    print(char.numpy(), int2char[char.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2de9146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿project gutenbergs alices adventures in wonderland by lewis carroll\n",
      "\n",
      "\n",
      "\n",
      "this ebook is for the use of anyone anywhere at no cost and with\n",
      "\n",
      "almost no restrictions whatsoever  you may copy it give it away\n",
      " or\n",
      "\n",
      "reuse it under the terms of the project gutenberg license included\n",
      "\n",
      "with this ebook or online at wwwgutenbergorg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "title alices adventures in wonderland\n",
      "\n",
      "\n",
      "\n",
      "author lewis carroll\n",
      "\n",
      "\n",
      "\n",
      "posting date \n"
     ]
    }
   ],
   "source": [
    "# build sequences by batching\n",
    "sequences = char_dataset.batch(2*sequence_length + 1, drop_remainder=True)\n",
    "\n",
    "# print sequences\n",
    "for sequence in sequences.take(2):\n",
    "    print(''.join([int2char[i] for i in sequence.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "529443c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sample(sample):\n",
    "    # example :\n",
    "    # sequence_length is 10\n",
    "    # sample is \"python is a great pro\" (21 length)\n",
    "    # ds will equal to ('python is ', 'a') encoded as integers\n",
    "    ds = tf.data.Dataset.from_tensors((sample[:sequence_length], sample[sequence_length]))\n",
    "    for i in range(1, (len(sample)-1) // 2):\n",
    "        # first (input_, target) will be ('ython is a', ' ')\n",
    "        # second (input_, target) will be ('thon is a ', 'g')\n",
    "        # third (input_, target) will be ('hon is a g', 'r')\n",
    "        # and so on\n",
    "        input_ = sample[i: i+sequence_length]\n",
    "        target = sample[i+sequence_length]\n",
    "        # extend the dataset with these samples by concatenate() method\n",
    "        other_ds = tf.data.Dataset.from_tensors((input_, target))\n",
    "        ds = ds.concatenate(other_ds)\n",
    "    return ds\n",
    "\n",
    "# prepare inputs and targets\n",
    "dataset = sequences.flat_map(split_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7bb07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_samples(input_, target):\n",
    "    # onehot encode the inputs and the targets\n",
    "    # Example:\n",
    "    # if character 'd' is encoded as 3 and n_unique_chars = 5\n",
    "    # result should be the vector: [0, 0, 0, 1, 0], since 'd' is the 4th character\n",
    "    return tf.one_hot(input_, n_unique_chars), tf.one_hot(target, n_unique_chars)\n",
    "\n",
    "dataset = dataset.map(one_hot_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6392e522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ﻿project gutenbergs alices adventures in wonderland by lewis carroll\n",
      "\n",
      "\n",
      "\n",
      "this ebook is for the use of\n",
      "Target:  \n",
      "Input shape: (100, 39)\n",
      "Target shape: (39,)\n",
      "================================================== \n",
      "\n",
      "Input: project gutenbergs alices adventures in wonderland by lewis carroll\n",
      "\n",
      "\n",
      "\n",
      "this ebook is for the use of \n",
      "Target: a\n",
      "Input shape: (100, 39)\n",
      "Target shape: (39,)\n",
      "================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print first 2 samples\n",
    "for element in dataset.take(2):\n",
    "    print(\"Input:\", ''.join([int2char[np.argmax(char_vector)] for char_vector in element[0].numpy()]))\n",
    "    print(\"Target:\", int2char[np.argmax(element[1].numpy())])\n",
    "    print(\"Input shape:\", element[0].shape)\n",
    "    print(\"Target shape:\", element[1].shape)\n",
    "    print(\"=\"*50, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5e2f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat, shuffle and batch the dataset\n",
    "ds = dataset.repeat().shuffle(1024).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "411060c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(256, input_shape=(sequence_length, n_unique_chars), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(256),\n",
    "    Dense(n_unique_chars, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd8a6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 256)          303104    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 256)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 39)                10023     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 838,439\n",
      "Trainable params: 838,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the model path\n",
    "model_weights_path = f\"results/{BASENAME}-{sequence_length}.h5\"\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b53ca91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1238/1238 [==============================] - 1657s 1s/step - loss: 2.2210 - accuracy: 0.3586\n",
      "Epoch 2/30\n",
      "1238/1238 [==============================] - 1663s 1s/step - loss: 1.7236 - accuracy: 0.4872\n",
      "Epoch 3/30\n",
      "1238/1238 [==============================] - 1596s 1s/step - loss: 1.5256 - accuracy: 0.5403\n",
      "Epoch 4/30\n",
      "1238/1238 [==============================] - 1557s 1s/step - loss: 1.3823 - accuracy: 0.5801\n",
      "Epoch 5/30\n",
      "1238/1238 [==============================] - 1530s 1s/step - loss: 1.2611 - accuracy: 0.6126\n",
      "Epoch 6/30\n",
      "1238/1238 [==============================] - 1463s 1s/step - loss: 1.1515 - accuracy: 0.6433\n",
      "Epoch 7/30\n",
      "1238/1238 [==============================] - 1378s 1s/step - loss: 1.0458 - accuracy: 0.6731\n",
      "Epoch 8/30\n",
      "1238/1238 [==============================] - 1320s 1s/step - loss: 0.9551 - accuracy: 0.6980\n",
      "Epoch 9/30\n",
      "1238/1238 [==============================] - 1223s 988ms/step - loss: 0.8700 - accuracy: 0.7240\n",
      "Epoch 10/30\n",
      "1238/1238 [==============================] - 1216s 982ms/step - loss: 0.7956 - accuracy: 0.7454\n",
      "Epoch 11/30\n",
      "1238/1238 [==============================] - 1252s 1s/step - loss: 0.7260 - accuracy: 0.7667\n",
      "Epoch 12/30\n",
      "1238/1238 [==============================] - 1212s 979ms/step - loss: 0.6701 - accuracy: 0.7829\n",
      "Epoch 13/30\n",
      "1238/1238 [==============================] - 1230s 994ms/step - loss: 0.6163 - accuracy: 0.8002\n",
      "Epoch 14/30\n",
      "1238/1238 [==============================] - 1230s 993ms/step - loss: 0.5750 - accuracy: 0.8120\n",
      "Epoch 15/30\n",
      "1238/1238 [==============================] - 1336s 1s/step - loss: 0.5360 - accuracy: 0.8244\n",
      "Epoch 16/30\n",
      "1238/1238 [==============================] - 1496s 1s/step - loss: 0.4987 - accuracy: 0.8364\n",
      "Epoch 17/30\n",
      "1238/1238 [==============================] - 1222s 987ms/step - loss: 0.4681 - accuracy: 0.8448\n",
      "Epoch 18/30\n",
      "1238/1238 [==============================] - 1277s 1s/step - loss: 0.4428 - accuracy: 0.8533\n",
      "Epoch 19/30\n",
      "1238/1238 [==============================] - 1338s 1s/step - loss: 0.4191 - accuracy: 0.8599\n",
      "Epoch 20/30\n",
      "1238/1238 [==============================] - 1341s 1s/step - loss: 0.3981 - accuracy: 0.8675\n",
      "Epoch 21/30\n",
      "1238/1238 [==============================] - 1314s 1s/step - loss: 0.3830 - accuracy: 0.8724\n",
      "Epoch 22/30\n",
      "1238/1238 [==============================] - 1308s 1s/step - loss: 0.3655 - accuracy: 0.8774\n",
      "Epoch 23/30\n",
      "1238/1238 [==============================] - 1311s 1s/step - loss: 0.3489 - accuracy: 0.8825\n",
      "Epoch 24/30\n",
      "1238/1238 [==============================] - 1482s 1s/step - loss: 0.3324 - accuracy: 0.8881\n",
      "Epoch 25/30\n",
      "1238/1238 [==============================] - 1214s 981ms/step - loss: 0.3201 - accuracy: 0.8926\n",
      "Epoch 26/30\n",
      "1238/1238 [==============================] - 31194s 25s/step - loss: 0.3118 - accuracy: 0.8949\n",
      "Epoch 27/30\n",
      "1238/1238 [==============================] - 1386s 1s/step - loss: 0.3042 - accuracy: 0.8969\n",
      "Epoch 28/30\n",
      "1238/1238 [==============================] - 1207s 975ms/step - loss: 0.2961 - accuracy: 0.9000\n",
      "Epoch 29/30\n",
      "1238/1238 [==============================] - 1480s 1s/step - loss: 0.2855 - accuracy: 0.9035\n",
      "Epoch 30/30\n",
      "1238/1238 [==============================] - 1486s 1s/step - loss: 0.2818 - accuracy: 0.9044\n"
     ]
    }
   ],
   "source": [
    "# make results folder if does not exist yet\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "# train the model\n",
    "model.fit(ds, steps_per_epoch=(len(encoded_text) - sequence_length) // BATCH_SIZE, epochs=EPOCHS)\n",
    "# save the model\n",
    "model.save(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5128dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Activation\n",
    "import os\n",
    "\n",
    "sequence_length = 100\n",
    "# dataset file path\n",
    "FILE_PATH = \"sample1.txt\"\n",
    "# FILE_PATH = \"data/python_code.py\"\n",
    "BASENAME = os.path.basename(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eca0ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"chapter xiii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d18164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocab dictionaries\n",
    "char2int = pickle.load(open(f\"{BASENAME}-char2int.pickle\", \"rb\"))\n",
    "int2char = pickle.load(open(f\"{BASENAME}-int2char.pickle\", \"rb\"))\n",
    "vocab_size = len(char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f0592b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "model = Sequential([\n",
    "    LSTM(256, input_shape=(sequence_length, vocab_size), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(256),\n",
    "    Dense(vocab_size, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cc77289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the optimal weights\n",
    "model.load_weights(f\"results/{BASENAME}-{sequence_length}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07b175f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating text: 100%|███████████████████████████████████████████████████████████████| 400/400 [00:21<00:00, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: chapter xiii\n",
      "Generated text:\n",
      " aloce she went on in\n",
      "\n",
      "the pat open out im to a dony wrote i wonder which way to find in a more\n",
      "\n",
      "hop question the gryphon and the fan and garden and make out the grow of alice and wondering why i dont get out\n",
      "\n",
      "a tream seall\n",
      "\n",
      "beaster alice as she remembered\n",
      "\n",
      "of minute or two she began on by paristing the branch of her however it was good rupbis do and be read\n",
      "\n",
      "\n",
      "\n",
      "and with to its generally\n",
      "\n",
      "offended \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = seed\n",
    "n_chars = 400\n",
    "# generate 400 characters\n",
    "generated = \"\"\n",
    "for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
    "    # make the input sequence\n",
    "    X = np.zeros((1, sequence_length, vocab_size))\n",
    "    for t, char in enumerate(seed):\n",
    "        X[0, (sequence_length - len(seed)) + t, char2int[char]] = 1\n",
    "    # predict the next character\n",
    "    predicted = model.predict(X, verbose=0)[0]\n",
    "    # converting the vector to an integer\n",
    "    next_index = np.argmax(predicted)\n",
    "    # converting the integer to a character\n",
    "    next_char = int2char[next_index]\n",
    "    # add the character to results\n",
    "    generated += next_char\n",
    "    # shift seed and the predicted character\n",
    "    seed = seed[1:] + next_char\n",
    "\n",
    "print(\"Seed:\", s)\n",
    "print(\"Generated text:\")\n",
    "print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
